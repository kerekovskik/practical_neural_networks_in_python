{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Functions\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the role of cost functions in neural networks\n",
    "- Compare different types of cost functions\n",
    "- Understand the relation between the problem at hand and the choice of cost function\n",
    "- Understand real-world examples where different cost functions might be used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Cost Functions\n",
    "\n",
    "In the context of neural networks, a cost function (also known as a loss function or objective function) is a measure of how far off our model's predictions are from the actual outcomes. It can be thought of as the 'GPS navigation' for our model, guiding the learning algorithm to the right solution in the vast 'terrain' of parameter space. The cost function provides feedback on the model's performance that is used to adjust the weights and biases, in the process known as backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Cost Functions\n",
    "\n",
    "Different types of problems require different types of cost functions. The most common cost functions are:\n",
    "\n",
    "- Mean Squared Error (MSE)\n",
    "- Cross-Entropy\n",
    "- Log Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)\n",
    "\n",
    "Mean Squared Error (MSE) is commonly used in regression problems. The MSE calculates the average squared difference between the predicted and actual outcomes.\n",
    "\n",
    "Mathematically, it is defined as:\n",
    "\n",
    "MSE = $\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "where $y_i$ is the actual value, $\\hat{y}_i$ is the predicted value, and $N$ is the total number of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy\n",
    "\n",
    "Cross-Entropy is commonly used in binary classification problems. It measures the dissimilarity between the actual and predicted probability distribution.\n",
    "\n",
    "Mathematically, it is defined as:\n",
    "\n",
    "Cross-Entropy = $-\\sum_{i=1}^{N} y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)$\n",
    "\n",
    "where $y_i$ is the actual value, $\\hat{y}_i$ is the predicted value, and $N$ is the total number of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Loss\n",
    "\n",
    "Log Loss is used in multi-class classification problems. Like Cross-Entropy, it measures the dissimilarity between the actual and predicted probability distributions.\n",
    "\n",
    "Mathematically, it is defined as:\n",
    "\n",
    "Log Loss = $-\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{M} y_{ij} \\log(\\hat{y}_{ij})$\n",
    "\n",
    "where $y_{ij}$ is the actual value of the jth class for the ith instance, $\\hat{y}_{ij}$ is the predicted value of the jth class for the ith instance, $N$ is the total number of data points, and $M$ is the total number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The choice of cost function depends on the problem at hand\n",
    "\n",
    "In practice, the choice of cost function can depend on the nature of the problem:\n",
    "\n",
    "- **Regression problems** typically use the Mean Squared Error (MSE) because it penalizes larger errors more due to the squaring operation.\n",
    "- **Binary classification problems** often use the Cross-Entropy loss as it provides a more nuanced feedback for classification tasks by comparing the model's predicted probabilities with the actual classes.\n",
    "- **Multi-class classification problems** often use the Log Loss as it extends the idea of Cross-Entropy to multiple classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world Examples\n",
    "\n",
    "Different cost functions are used in various types of machine learning tasks:\n",
    "\n",
    "- **Mean Squared Error (MSE)** is often used in tasks such as house price prediction, where the task is to predict a continuous value.\n",
    "\n",
    "- **Cross-Entropy** is often used in tasks like email spam detection, where the task is to classify an email as spam or not spam.\n",
    "\n",
    "- **Log Loss** is often used in tasks like handwritten digit recognition, where the task is to classify an image into one of several classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
