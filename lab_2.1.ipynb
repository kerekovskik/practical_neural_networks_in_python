# Cell 1
# Required Libraries
import numpy as np

# Markdown Cell 2
## Understanding Neurons and the Architecture of Neural Networks

# Markdown Cell 3
### Neurons and Layers in a Neural Network
Neurons, or nodes, are organized into layers to form a neural network. A neural network typically consists of three types of layers: 
- The input layer: Where your data enters the network. The nodes in this layer correspond to the features in your data.
- Hidden layers: These are between the input and output layers. They don't directly interact with the external environment - we neither feed data into them nor get results from them. Instead, they transform the input data in such a way that the output layer can make a useful prediction.
- The output layer: The final layer in the network where the results of all the previous computations get consolidated and presented as the network's prediction or classification【9†source】.

# Cell 4
# Let's create a basic representation of these layers using lists in Python.
input_layer = ['Feature 1', 'Feature 2']
hidden_layers = [['Node 1', 'Node 2'], ['Node 3', 'Node 4', 'Node 5']]
output_layer = ['Output']

# Cell 5
# Printing our layers
print(f'Input Layer: {input_layer}')
print(f'Hidden Layers: {hidden_layers}')
print(f'Output Layer: {output_layer}')

# Markdown Cell 6
### Depth and Width of a Neural Network
The depth of a neural network is determined by the number of layers it has. A network with just an input and an output layer is called a shallow network. When we add one or more hidden layers between the input and output layers, we create a deep neural network. Width, on the other hand, refers to the number of neurons in a layer. A wider layer can learn more features from the same data, essentially giving the network a broader 'perspective'【9†source】.

# Cell 7
# Depth and Width of our basic network
depth = len(hidden_layers) + 2 # Adding 2 to account for input and output layers
width = max([len(layer) for layer in [input_layer, *hidden_layers, output_layer]])

print(f'Depth of the network: {depth}')
print(f'Maximum width of the network: {width}')

# Markdown Cell 8
### Forward Propagation in a Neural Network
When we feed data into a neural network, it travels through the layers, getting transformed along the way until it reaches the output layer. This process is known as forward propagation【9†source】.

# Markdown Cell 9
#### Implementing a Simple Neuron
We'll begin by implementing a simple neuron in Python. For this, we'll create a binary classifier with a single feature. This neuron will use the sigmoid activation function.

# Cell 10
# Sigmoid activation function
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Cell 11
# Testing our sigmoid function with some values
print(f'Sigmoid of -10 is {sigmoid(-10)}')
print(f'Sigmoid of 0 is {sigmoid(0)}')
printSure, let's continue from where we left off.

```python
# Cell 12
# Define a single neuron
class Neuron:
    def __init__(self, weights, bias):
        self.weights = weights
        self.bias = bias

    def forward(self, inputs):
        # Calculate the net input for this neuron
        total = np.dot(self.weights, inputs) + self.bias
        return sigmoid(total)

# Markdown Cell 13
#### Implementing a Simple Neural Network
Now, let's move on to implement a simple neural network in Python using NumPy. We'll organize neurons into layers and implement forward propagation. 

# Cell 14
# Define a layer of neurons
class NeuralLayer:
    def __init__(self, neurons):
        self.neurons = neurons

    def forward(self, inputs):
        # Forward the input through all neurons in the layer
        return np.array([neuron.forward(inputs) for neuron in self.neurons])

# Cell 15
# Define a neural network
class NeuralNetwork:
    def __init__(self, layers):
        self.layers = layers

    def forward(self, inputs):
        # Forward the input through all layers
        current_output = inputs
        for layer in self.layers:
            current_output = layer.forward(current_output)
        return current_output

# Cell 16
# Testing our classes with an example
weights = np.array([0, 1])  # example weights
bias = 4   # example bias
inputs = np.array([2, 3])  # example inputs

# Create a neuron
neuron = Neuron(weights, bias)
print(f'Output of a single neuron: {neuron.forward(inputs)}')

# Create a layer with the same neuron
layer = NeuralLayer([neuron, neuron, neuron])
print(f'Output of a neural layer: {layer.forward(inputs)}')

# Create a network with the same layer
network = NeuralNetwork([layer, layer])
print(f'Output of a neural network: {network.forward(inputs)}')

# Markdown Cell 17
## Discussion and Questions
Discuss potential problems and the solutions offered by the architecture of neural networks. 

1. How does the architecture of a neural network contribute to its learning capability?
2. What are the trade-offs of having a deeper or wider network?
3. How does the forward propagation process work in a neural network?
4. Why are the weights and biases important in a neural network?

# Markdown Cell 18
## Homework Assignment
Implement a simple multi-layer neural network in Python. Experiment with different numbers of layers and neurons and observe how the network's complexity affects its behavior【13†source】.

# Cell 19
# Your implementation here

# Cell 20
# Your implementation here
